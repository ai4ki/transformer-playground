{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3c78a5f",
   "metadata": {},
   "source": [
    "# GPT-3 Playground\n",
    "\n",
    "*Last updated: 01/31/2022*\n",
    "\n",
    "This notebook allows you to experiment with OpenAI's GPT-3 language model. We took the example applications from OpenAI's [playground](https://beta.openai.com/examples). \n",
    "\n",
    "Note that OpenAI's API is a charged service. Using it requires credentials, which you can apply for  [here](https://openai.com/api/).\n",
    "\n",
    "**Also note that GPT-3 imbues other costs: those on our climate. We therefore ask you to use it with restraint.**\n",
    "\n",
    "\n",
    "## Working with Jupyter notebooks\n",
    "\n",
    "In case you are not familiar with Jupyter notebooks, this is how to go about it: In order to execute a piece of code, click inside a cell (the ones with `[]` to the left) and press Shift+Enter. Wait until the cell is done--that's when the `*` in `[]` turned into a number--and move on to the next cell.\n",
    "\n",
    "If you get inconceivable error messages or the notebook gets stuck, choose \"Restart & Clear Output\" in the \"Kernel\" dropdown-menu above.\n",
    "___\n",
    "**Please help us to improve this tool by [emailing us](mailto:ai4ki.dev@gmail.com?subject=ai4ki-tools:%20GPT-3%20Playground) your update ideas or error reports.**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b61fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de14e6",
   "metadata": {},
   "source": [
    "### Provide API key\n",
    "*Exceute the cell, enter your OpenAI API-key in the input field below, and hit enter.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d24472",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = input('Enter your OpenAI API key: ')\n",
    "print('API key accepted: ', API_KEY)\n",
    "openai.api_key = API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83ddc2a",
   "metadata": {},
   "source": [
    "## 1: Text Generation\n",
    "GPT-3 can generate new text based on a user's input (also called a 'prompt'). A prompt can be anything: a blank, a question, the first few words of a sentence, or the beginning of a story. The best results are obtained with English language prompts as GPT-3's training data was mostly English text. You can, however, try any other language as well. Prompting is becoming an art form of sorts, because giving the model the right instrtcutions decides on the variety of taks you can use it for (for an overview of prompt desgin see [here](https://thegradient.pub/prompting/)). We return to this issue throughout the notebook. \n",
    "\n",
    "*Enter your prompt between the quotation marks below and run the cell.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6885faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"In the future, scientists will be replaced by \"\n",
    "user_prompt = user_prompt.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f0898",
   "metadata": {},
   "source": [
    "The output of GPT-3 can be tuned with different parameters, the most important of which is `temperature`. Roughly speaking, temperature controls the randomness of the output. Values close to zero will more likely create repetitive text, while larger values allow GPT-3 to be more 'creative'. You can experiment with different values by changing the parameter in the cell below.\n",
    "\n",
    "*Run the following cell to have GPT-3 complete your prompt.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aed2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = text_generation(\n",
    "    user_prompt,\n",
    "    temperature=0.7,\n",
    "    token_limit=512, # Maximum lenght of input and output--don't change this value unless you pay the bill!\n",
    "    max_tokens=128,  # Maximum lenght of output\n",
    "    )\n",
    "print(user_prompt+response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb708759",
   "metadata": {},
   "source": [
    "## 2: Sentiment Analysis\n",
    "Sentiment analysis is one of the most common applications in NLP. Although GPT-3 was not explicitly trained for this task, it handles it surprisingly well. You can try this out for yourself below, by comparing GPT-3's classification of a tweet-like prompt with that of a state-of-the-art sentiment classifier ([SpaCy's TextBlob](https://spacy.io/universe/project/spacy-textblob))\n",
    "\n",
    "*Enter your prompt between the quotation marks below and run the cell.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229a7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Apples are the most delicious of fruits!\"\n",
    "user_prompt = user_prompt.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb8564",
   "metadata": {},
   "source": [
    "*Run the following cell to have GPT-3 classify your prompt.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7edb58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_gpt3, full_prompt = gpt3_classifier(user_prompt)\n",
    "print(reply_gpt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f802e85",
   "metadata": {},
   "source": [
    "*Run the following cell to have SpaCy classify your prompt.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf3a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_spacy, _, _ = spacy_classifier(user_prompt)\n",
    "print(reply_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f85de53",
   "metadata": {},
   "source": [
    "The secret for GPT-3's sentiment analysis capability lies in the prompt design. Instead of sending the model your prompt as is, we changed it in the background in a particular way. Run the following cell to see the full prompt as sent to GPT-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9070917e",
   "metadata": {},
   "source": [
    "## 3: Sci-Lang to Lite-Slang \n",
    "This is another example, which demonstrates GPT-3's versatility: We ask it to simplify a complicated text for us. The application we here have in mind is' helping scientists to write texts, which a broader audience can better understand.\n",
    "\n",
    "*Enter your text between the triple quotation marks below and run the cell.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d2904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = '''\n",
    "Returning to the issue of the historical record,\n",
    "even if one bolsters the claim that AI started at the 1956\n",
    "conference by adding the proviso that 'artificial intelligence'\n",
    "refers to a nuts-and-bolts engineering pursuit (in which case\n",
    "Turing's philosophical discussion, despite calls for a child machine,\n",
    "wouldnâ€™t exactly count as AI per se), one must confront the fact that\n",
    "Turing, and indeed many predecessors, did attempt to build intelligent artifacts.\n",
    "'''\n",
    "user_prompt = user_prompt.strip().replace('\\n',' ')\n",
    "# Example text taken from Stanford Encyclopedia of Philosophy, Article \"Artificial Intelligence\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641a3980",
   "metadata": {},
   "source": [
    "*Run the following cell to have GPT-3 simplify your text.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce337cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lite_slang, full_prompt = science_translator(user_prompt, engine=\"davinci\", trunc=False)\n",
    "print(lite_slang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2128d",
   "metadata": {},
   "source": [
    "The trick here is also prompt design. Run the following cell to see the full prompt we've sent to GPT-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b9c62",
   "metadata": {},
   "source": [
    "## 4: Summarization\n",
    "Large language models like GPT-3 are also able to summarize text. Following OpenAI's example, here we simply add the string 'Tl;dr' (*Too long; don't read*) to the input text. GPT-3 recognizes this as a prompt to create a short summary of the input text. You might want to compare GPT-3's summaries with those of other transformers by heading to this [notebook](https://github.com/ai4ki/summarization.git).\n",
    "\n",
    "*Enter your text between the triple quotation marks below and run the cell.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e6d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = '''\n",
    "Your text here!\n",
    "'''\n",
    "user_prompt = user_prompt.strip().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1fd1c7",
   "metadata": {},
   "source": [
    "*Run the following cell to have GPT-3 generate a summary of your text.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d11887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = user_prompt + \"\\n\\nTl;dr:\"\n",
    "response = text_generation(\n",
    "    user_prompt,\n",
    "    temperature=0.9,\n",
    "    top_p=1.0,\n",
    "    token_limit=512, # Maximum lenght of input and output--don't change this value unless you pay the bill!\n",
    "    max_tokens=128,  # Maximum lenght of output\n",
    "    trunc=True\n",
    "    )\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ba17bc",
   "metadata": {},
   "source": [
    "## 5: Chatbot\n",
    "Finally, GPT-3 can be used to create a chatbot with character, which is able to converse about anything.\n",
    "\n",
    "*Run the cell below and talk to an AI that's instructed to be chatty and charming. If you want to end the conversation type 'stop'.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b878da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = input(\"You: \")\n",
    "chatbot(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1ceeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:openai_projects]",
   "language": "python",
   "name": "conda-env-openai_projects-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
